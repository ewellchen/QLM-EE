[COMMON]
# Generic
seed = 666
datasets_dir = data
dataset_name = wiki

# Preprocess
remove_punctuation= 0
stem = 0
remove_stopwords = 0
clean = 1
clean_sentence = 1
max_len = 100

# Network
network_type = Entangled
activation = sigmoid
ngram_value = 1,2,3
measurement_size  = 200,5000,10
pooling_type = max
match_type = pairwise
margin = 0.1
distance_type = 6
onehot = 0
train_verbose = 0
map_dimension = 8
hidden_neuron = 16,32,12


# Training
optimizer = rmsprop
batch_size = 32
epochs = 150
embedding_trainable = True
random_init = 1
amplitude_l2 = 0.00000005
phase_l2 = 0
dropout_rate_probs = 0.8
dense_l2 = 0
lr = 0.1

# Evaluation
eval_dir = eval
output_file = result_wiki_0305.txt
